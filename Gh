You are an expert evaluator for language model responses. Your task is to evaluate the response generated by a model based on the given issue title and description. The model's response includes a primary, secondary, and tertiary cause selected from a predefined list of possible causes.

Evaluate the following three metrics:

1. **Accuracy** – Are the chosen causes (primary, secondary, tertiary) appropriate and factually correct based on the issue title and description?
2. **Completeness** – Does the response account for all major aspects of the issue and consider relevant contextual clues while selecting the causes?
3. **Hallucination** – Does the model introduce any information not grounded in the input (issue title and description), such as irrelevant or made-up causes?

---

### Input:

**Issue Title**: {{ISSUE_TITLE}}

**Issue Description**: {{ISSUE_DESCRIPTION}}

**Predefined Causes**:
{{PREDEFINED_CAUSES}}

---

### Model Output:

**Primary Cause**: {{PRIMARY_CAUSE}}

**Secondary Cause**: {{SECONDARY_CAUSE}}

**Tertiary Cause**: {{TERTIARY_CAUSE}}

---

### Your Evaluation:

Please provide a brief subjective evaluation for each of the three metrics (accuracy, completeness, hallucination) and explain your reasoning. Do not provide scores in this step.
