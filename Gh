The ongoing monitoring plan must outline the extent to which AI-generated outputs are used without modification and whether users validate the accuracy and reliability of the model’s output.

4.1 Extent of AI Output Usage
The RMC Risk Management Copilot generates structured outputs based on issue descriptions and titles, following the 5C’s framework.

The AI-generated output is not directly used without human review. Risk management role holders are expected to:

Verify the structured output to ensure it aligns with their risk assessment needs.

Modify the output as required before final documentation and storage in Helios.

4.2 Accuracy and Reliability Checks
Since the model primarily restructures input data rather than generating entirely new content, the risk of hallucination is low. However, accuracy checks remain critical.

The model’s accuracy, completeness, and hallucination detection metrics are monitored continuously to assess performance.

If an accuracy threshold is not met, users are prompted to review and refine the output before finalization.

In cases where key components are missing, the model suggests additional information that may be required.

5. Action Plan for Performance Degradation
The ongoing monitoring plan must define the action plan in case of performance degradation, including early warning signals, alert mechanisms, and mitigation steps.

5.1 Early Warning Signals
Performance degradation is detected using predefined thresholds for monitoring metrics, visualized on the dashboard using a color-coded system:

Metric	Red (0-49%)	Amber (50-69%)	Green (70-98%)	Purple (98-100%)
Accuracy	Needs immediate intervention	Moderate risk, requires review	Acceptable range	Potential overconfidence
Completeness	Critical gaps in structured output	Some missing components	All required elements present	NA
Hallucination	AI-generated incorrect content	Potential inconsistencies	No hallucination detected	NA
Red Alerts indicate critical failure and require immediate investigation.

Amber Alerts suggest potential issues and prompt a manual review of model outputs.

Green represents a normal range of performance.

Purple indicates potential overconfidence, requiring analysis to avoid misinterpretation.

5.2 Alert Mechanism and Mitigation Steps
The system employs real-time monitoring with the following alert mechanisms:

Dashboard notifications: Visual alerts update in real-time.

Email alerts: If accuracy falls below 50% (Red Zone), an automated notification is sent to the monitoring team.

Trend analysis: Historical data is analyzed to detect performance declines over time.

Mitigation Steps for Performance Degradation:

Investigate Model Outputs: Identify patterns in low-scoring responses (e.g., frequent missing components, inaccuracies).

User Feedback Collection: Engage risk management users to determine if model-generated drafts require excessive modification.

Model Refinement: Adjust prompt engineering, data preprocessing, or retraining strategies based on observed gaps.

Threshold Recalibration: If needed, adjust alert thresholds based on business needs and evolving performance trends.

This structured action plan ensures that any decline in model performance is detected early, investigated thoroughly, and addressed proactively to maintain output quality and reliability.

