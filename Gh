import pandas as pd
import unicodedata
import re

# Sample DataFrame with messy strings
df = pd.DataFrame({
    'title': ['Python for “Data” Science', 'AI\tin Healthcare\n', 'Machine\u201c Learning', "Cloud's Edge"]
})

# Set of substrings to check
search_set = {'Python', 'AI', 'Data', 'Machine Learning', 'Cloud'}

# Function to clean a string
def clean_text(text):
    if not isinstance(text, str):
        return ''
    text = unicodedata.normalize('NFKD', text)     # Normalize unicode
    text = text.encode('ascii', 'ignore').decode() # Remove non-ascii
    text = text.replace('\n', ' ').replace('\t', ' ')  # Remove escape chars
    text = re.sub(r'[“”‘’"\'`]', '', text)         # Remove quotes
    text = re.sub(r'\s+', ' ', text).strip()       # Collapse whitespace
    return text.lower()                            # Optional: case-insensitive

# Clean all titles and combine into a single text block
all_text = ' '.join(df['title'].apply(clean_text))

# Now check which terms from the set are not present
not_found = {term for term in search_set if clean_text(term) not in all_text}

print("Terms not found as substring:", not_found)
