Step-by-Step Explanation:
1. Input and Output Text
We define:

input_text: The original text prompt or input to the LLM.
output_text: The AI-generated response.
Example:

plaintext
Copy code
Input: "Explain the benefits of renewable energy."  
Output: "Renewable energy is clean and sustainable. It can also be used to generate wind energy, which powers devices. Fossil fuels are very expensive."
2. Tokenize Output into Sentences
We split the AI-generated output into individual sentences using sent_tokenize() from the nltk library.
This allows us to analyze one sentence at a time.

Example:

plaintext
Copy code
Output sentences:
1. "Renewable energy is clean and sustainable."
2. "It can also be used to generate wind energy, which powers devices."
3. "Fossil fuels are very expensive."
3. Generate Embeddings
We generate OpenAI Ada embeddings for:
The input text.
Each output sentence.
The function get_embedding() handles this by calling the OpenAI API and returning a numerical embedding for the text.

Example:

python
Copy code
input_embedding = get_embedding(input_text)
sentence_embedding = get_embedding(sentence)
4. Cosine Similarity
We calculate the cosine similarity between the input embedding and each sentence embedding:

Cosine Similarity
=
A
⋅
B
∥
A
∥
∥
B
∥
Cosine Similarity= 
∥A∥∥B∥
A⋅B
​
 
A = Input embedding.

B = Sentence embedding.

A high similarity (close to 1) means the sentence is semantically related to the input.

A low similarity (e.g., < 0.6) suggests the sentence may be irrelevant or hallucinated.

5. Flag Hallucinated Sentences
For each sentence:

If the cosine similarity is below 0.6, the sentence is flagged as a hallucination.
python
Copy code
hallucination_flags.append(similarity < 0.6)
6. Count Hallucinated Sentences
We sum up all the flagged sentences and report the number of hallucinated sentences relative to the total.

python
Copy code



import numpy as np
import openai

openai.api_key = "your-api-key"

def get_embedding(text, model="text-embedding-ada-002"):
    response = openai.Embedding.create(input=text, model=model)
    return np.array(response['data'][0]['embedding'])

# Input and output texts
input_text = "Explain the benefits of renewable energy."
output_text = "Renewable energy is clean and sustainable. Fossil fuels are costly."

# Generate embeddings
input_embedding = get_embedding(input_text)
output_embedding = get_embedding(output_text)

# Cosine similarity
cosine_similarity = np.dot(input_embedding, output_embedding) / (
    np.linalg.norm(input_embedding) * np.linalg.norm(output_embedding)
)

# Set threshold for hallucination
if cosine_similarity < 0.6:
    print("Hallucination detected in the output.")
else:
    print("Output aligns with the input.")



import numpy as np

# Example embeddings (1536-dimensional vectors)
embedding_text1 = np.random.rand(1536)  # Replace with your actual embedding
embedding_text2 = np.random.rand(1536)  # Replace with your actual embedding

def cosine_similarity(vec1, vec2):
    # Calculate cosine similarity
    dot_product = np.dot(vec1, vec2)
    norm_vec1 = np.linalg.norm(vec1)
    norm_vec2 = np.linalg.norm(vec2)
    return dot_product / (norm_vec1 * norm_vec2)

# Calculate similarity
similarity_score = cosine_similarity(embedding_text1, embedding_text2)

print(f"Semantic Similarity: {similarity_score:.4f}")
